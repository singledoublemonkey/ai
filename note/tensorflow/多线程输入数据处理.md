
### 经典的数据输入处理流程：
``` graph TD
    A[指定原始数据文件列表] --> B[创建文件列表队列]
    B --> C[从文件中读取数据]
    C --> D[数据预处理]
    D --> E[整理成Batch作为神经网络输入]
```

1. 多线程管理：

tf.Coordinator()

```
# -*- coding: utf-8 -*-
'''
    线程管理测试
'''

import tensorflow as tf
import time
import threading
import numpy as np

def MyLoop(coord, work_id):

    while not coord.should_stop():

        if np.random.rand() < 0.1:
            print("Stop from id %d\n" % work_id)
            coord.request_stop()
        else:
            print("Work on id %d\n" % work_id)

        time.sleep(1)

coord = tf.train.Coordinator()

threads = [threading.Thread(target=MyLoop, args=(coord, i, )) for i in range(5)]

for t in threads:
    t.start()

coord.join(threads)
```

2. tf.QueueRunner
    
    tf.QueueRunner用于启动多个线程操作一个队列，启动的线程可以使用tf.Coordinator来管理


```
# -*- coding: utf-8 -*-
'''
    启动多线程操作同一个队列
'''
import tensorflow as tf

queue = tf.FIFOQueue(100, "float")

# 定义入队op
enqueue_op = queue.enqueue([tf.random_normal([1])])

# 创建多个线程入队的操作,5表示又5个线程，每个线程中都执行入队操作
qr = tf.train.QueueRunner(queue, [enqueue_op]*5)

# 将定义的QueueRunner加入tf的计算图指定的集合
tf.train.add_queue_runner(qr)

# 定义出队操作
out_tensor = queue.dequeue()

with tf.Session() as sess:
    # 启动Coordinator来管理线程
    coord = tf.train.Coordinator()
    # 启动所有线程
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)

    # 获取队列的数值
    for _ in range(5):
        print(sess.run(out_tensor)[0])

    # 停止所有线程
    coord.request_stop()
    coord.join(threads)
```
3. 输入文件队列

    当训练数据量较大时，可以分成多个TFRecord文件来提高处理效率。
    
    tensorflow中提供了tf.train.match_filenames_once函数获取符合正则表达式的所有文件，得到的文件可以通过tf.train.string_input_producer函数进行管理。
    
    示例：
    #### generate data：

```
import tensorflow as tf

def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

num_shards = 3

instance_per_shards = 10

for i in range(num_shards):
    filename = ('./file/data.tfrecords-%.5d-of-%.5d' % (i, num_shards))
    writer = tf.python_io.TFRecordWriter(filename)
    for j in range(instance_per_shards):
        example = tf.train.Example(features=tf.train.Features(feature={
            'i': _int64_feature(i),
            'j': _int64_feature(j)
        }))
        writer.write(example.SerializeToString())
    writer.close()
```
    #### get and use data
> shuffle=False时，不会打乱读取顺序。shuffle=True时，会打乱文件的读取顺序
```
import tensorflow as tf

files = tf.train.match_filenames_once('./file/data.tfrecords-*')

filename_queue = tf.train.string_input_producer(files, shuffle=True)

# Read and parse a example

reader = tf.TFRecordReader()
_, serialized_example = reader.read(filename_queue)

features = tf.parse_single_example(serialized_example, features={
    'i': tf.FixedLenFeature([], tf.int64),
    'j': tf.FixedLenFeature([], tf.int64)
})

with tf.Session() as sess:
    # 虽然没有用户变量需要初始化，但是match_filenames_once函数需要初始化一些变量
    tf.global_variables_initializer().run()
    print(sess.run(files))

    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess, coord)

    for i in range(15):
        print(sess.run([features['i'], features['j']]))
    coord.request_stop()
    coord.join(threads)
```

4. 组合训练数据（batching）
    
>在上一小节中，从文件获取的数据是单个数据形态。而在训练网络中，一般会采用batch的方式来训练数据，因此需要将获取的数据组织为batch形态以满足需求。

tf中有tf.train.batch函数和tf.train.shaffle_batch函数来处理。区别就是数据是否会被随机打乱进行组合。需要设置的参数是每个batch的大小，以及队列的容量capacity。（capacity=min_after_dequeue+3*batch, min_after_dequeue可以是1000或者10000或较大的值）

上述两个函数处理可以将获取的单条训练数据组装成batch之外，也提供了并行化处理方式。

num_threads参数，可以指定多个线程同时执行入队操作，此值大于1时，多个线程会同时读取一个文件中的不同样例进行预处理。

如果需要多个线程处理不同文件中的样例，可以使用tf.train.shuffle_batch_join函数。此函数会从输入文件中获取不同的文件分给不同的线程。
